Frontend:
  served_model_name: Qwen/QwQ-32B
  endpoint: dynamo.Processor.chat/completions
  port: 8000

Processor:
  model: /data/models/QwQ-32B
  router: round-robin
  trust-remote-code: true

VllmWorker:
  # vllm enging args
  model: /data/models/QwQ-32B
  served_model_name: Qwen/QwQ-32B
  kv-transfer-config: '{"kv_connector":"DynamoNixlConnector"}'
  trust-remote-code: true
  block-size: 64
  max-model-len: 32768
  max-num-batched-tokens: 32768
    # speculative-model: /data/models/Llama-3.2-1B
    # num-speculative-tokens: 5  # enable MTP
  tensor-parallel-size: 2
  enforce-eager: false # enable cudagraph
  # dynamo args
  remote-prefill: true
  conditional-disagg: true
  max-local-prefill-length: 64
  ServiceArgs:
    workers: 1
    resources:
      gpu: 2
